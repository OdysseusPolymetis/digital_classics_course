{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPlbttcBuGZYVGNfaMvlX6R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OdysseusPolymetis/digital_classics_course/blob/main/6_geolocalization_lat_gk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Géolocalisation avec Pleiades**"
      ],
      "metadata": {
        "id": "O7PBIeftNrQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour ça nous allons avoir besoin essentiellement de deux moteurs : un moteur de lemmatisation (stanza), et un moteur de détection d'entités nommées. Suite à cela, nous allons utiliser les données de Pleiades pour géolocaliser les entités trouvées."
      ],
      "metadata": {
        "id": "ywSAr8Csn28c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "T1L4tjl1NYzx"
      },
      "outputs": [],
      "source": [
        "!pip install flair\n",
        "!pip install stanza\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici on importe les bibliothèques dont on aura besoin, et comme pour tout modèle de type transformer, il vaut mieux avoir une GPU. Et nous lui disons de mettre le modèle sur la GPU.\n",
        "<br>Selon que vous aurez choisi un texte grec ou latin, vous aurez le modèle adéquat. Le modèle pour le latin sera sûrement moins bon que le modèle pour le grec. Pour le grec, on utilisera stanza, pour le latin on utilisera spacy (parce que c'est lui qui a le meilleur moteur de NER pour le latin)."
      ],
      "metadata": {
        "id": "UU0yb9FYoG5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C'est dans la cellule qui suit que vous devez préciser si vous faites du latin ou du grec, et donc `\"la\"` ou `\"grc\"`."
      ],
      "metadata": {
        "id": "D6ux-si3x3FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LANG = \"la\""
      ],
      "metadata": {
        "id": "KhTkoZLCsmB6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "import torch\n",
        "import flair\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device utilisé :\", DEVICE, \"| Langue :\", LANG)\n",
        "\n",
        "flair.device = torch.device(DEVICE)\n",
        "tagger = SequenceTagger.load(\"UGARIT/flair_grc_bert_ner\")\n",
        "tagger.to(DEVICE)"
      ],
      "metadata": {
        "id": "A9bKD5htN3RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import requests\n",
        "import folium\n",
        "from tqdm import tqdm\n",
        "\n",
        "import stanza\n",
        "import flair\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "MUqytqZcQNI7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici nous allons chercher les données de Pleiades, et nous les dézippons."
      ],
      "metadata": {
        "id": "QXAItBzOoQiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://atlantides.org/downloads/pleiades/gis/pleiades_gis_data.zip"
      ],
      "metadata": {
        "id": "s71xKozWN7_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip pleiades_gis_data.zip"
      ],
      "metadata": {
        "id": "vUIOuNj4O0DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici vous allez pouvoir mettre votre texte. Vous pouvez mettre du latin ou du grec."
      ],
      "metadata": {
        "id": "Nzib05j_oUJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "55dfmPB2SPae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "4704cb08-113c-41b0-9fc9-81f591e91f17"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c5aaa881-7ac5-4a12-a940-6b3cc236675c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c5aaa881-7ac5-4a12-a940-6b3cc236675c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving lat0690-003.txt to lat0690-003.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici il va vous falloir mettre les fichiers qui vous intéressent. Normalement vous n'avez à changer que la première ligne, celle du nom de votre txt."
      ],
      "metadata": {
        "id": "Xxlcf25jFCLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_PATH = \"/content/lat0690-003.txt\"\n",
        "NAMES_CSV = \"/content/data/gis/names.csv\"\n",
        "OUTPUT_MAP = \"map_ancient_places.html\""
      ],
      "metadata": {
        "id": "wOmUoNyDiJWG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction vous permet de:\n",
        "\n",
        "\n",
        "*   supprimer les diacritiques (accents)\n",
        "*   mettre en minuscules\n",
        "\n"
      ],
      "metadata": {
        "id": "g-CZ9prTFKjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_name(name: str) -> str:\n",
        "\n",
        "    if not isinstance(name, str):\n",
        "        return \"\"\n",
        "    return \"\".join(\n",
        "        c\n",
        "        for c in unicodedata.normalize(\"NFD\", name)\n",
        "        if unicodedata.category(c) != \"Mn\"\n",
        "    ).lower()"
      ],
      "metadata": {
        "id": "DHJYQJWbirYw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Là c'est une fonction de translittération très simplifiée du grec vers l'alphabet latin, si jamais les données Pleiades ne contiennent pas le grec nativement."
      ],
      "metadata": {
        "id": "R5j9GALRFWwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transliterate_greek_to_latin(s: str) -> str:\n",
        "\n",
        "    s = normalize_name(s)\n",
        "    table = {\n",
        "        'α': 'a',  'β': 'b',  'γ': 'g',   'δ': 'd',\n",
        "        'ε': 'e',  'ζ': 'z',  'η': 'e',   'θ': 'th',\n",
        "        'ι': 'i',  'κ': 'k',  'λ': 'l',   'μ': 'm',\n",
        "        'ν': 'n',  'ξ': 'x',  'ο': 'o',   'π': 'p',\n",
        "        'ρ': 'r',  'σ': 's',  'ς': 's',   'τ': 't',\n",
        "        'υ': 'u',  'φ': 'ph', 'χ': 'ch',  'ψ': 'ps',\n",
        "        'ω': 'o',\n",
        "    }\n",
        "    return \"\".join(table.get(ch, ch) for ch in s)"
      ],
      "metadata": {
        "id": "r--T5eFrivJM"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette partie-là vous donne un aperçu de votre texte en cours."
      ],
      "metadata": {
        "id": "cDtINY95FjUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(TEXT_PATH, encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(\"Longueur du texte :\", len(text), \"caractères\")\n",
        "print(\"Aperçu :\")\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B9lBDAWix3E",
        "outputId": "acbde388-ff52-4347-84dc-8e3617601fe6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longueur du texte : 443826 caractères\n",
            "Aperçu :\n",
            "       {AENEIS}         {LIBER I} Arma uirumque cano, Troiae qui primus ab oris Italiam fato profugus Lauiniaque uenit litora, multum ille et terris iactatus et alto ui superum, saeuae memorem Iunonis ob iram, multa quoque et bello passus, dum conderet urbem inferretque deos Latio; genus unde Latinum Albanique patres atque altae moenia Romae. Musa, mihi causas memora, quo numine laeso quidue dolens regina deum tot uoluere casus insignem pietate uirum, tot adire labores impulerit. tantaene animis caelestibus irae?     Vrbs antiqua fuit (Tyrii tenuere coloni) Karthago, Italiam contra Tiberinaque longe ostia, diues opum studiisque asperrima belli, quam Iuno fertur terris magis omnibus unam posthabita coluisse Samo. hic illius arma, hic currus fuit; hoc regnum dea gentibus esse, si qua fata sinant, iam tum tenditque fouetque. progeniem sed enim Troiano a sanguine duci audierat Tyrias olim quae uerteret arces; hinc populum late regem belloque superbum uenturum excidio Libyae; sic uoluere Pa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La cellule suivante charge le modèle stanza adéquat en fonction de la langue que vous avez demandée au départ."
      ],
      "metadata": {
        "id": "jdybctCtFoQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stanza.download(LANG)\n",
        "nlp = stanza.Pipeline(\n",
        "    lang=LANG,\n",
        "    processors=\"tokenize,lemma\",\n",
        "    use_gpu=(DEVICE == \"cuda\"),\n",
        "    device=DEVICE\n",
        ")"
      ],
      "metadata": {
        "id": "31vqcR75i0tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici on va utiliser deux types de moteurs NER, en fonction du grec ou du latin."
      ],
      "metadata": {
        "id": "ai1B1M9BFxXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if LANG == \"grc\":\n",
        "\n",
        "    flair.device = torch.device(DEVICE)\n",
        "    FLAIR_MODEL = \"UGARIT/flair_grc_bert_ner\"\n",
        "    tagger_grc = SequenceTagger.load(FLAIR_MODEL)\n",
        "    tagger_grc.to(DEVICE)\n",
        "    print(\"Modèle Flair grec chargé :\", FLAIR_MODEL)\n",
        "    ner_pipe_la = None\n",
        "\n",
        "elif LANG == \"la\":\n",
        "\n",
        "    device_id = 0 if DEVICE == \"cuda\" else -1\n",
        "    ner_pipe_la = pipeline(\n",
        "        \"token-classification\",\n",
        "        model=\"magistermilitum/roberta-multilingual-medieval-ner\",\n",
        "        device=device_id,\n",
        "    )\n",
        "    print(\"Pipeline NER latin (Transformers) initialisé.\")\n",
        "    tagger_grc = None"
      ],
      "metadata": {
        "id": "XAvlKMtZi554"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction fusionne les sous-mots renvoyés par roberta-multilingual-medieval-ner en entités complètes, en utilisant les offsets de caractères (logique proche de la TextProcessor du model card).\n",
        "\n",
        "    raw_ents : liste de dicts du pipeline HF\n",
        "               (avec 'entity' ou 'entity_group' ou 'label', 'word', 'start', 'end')\n",
        "    sent_text : texte brut de la phrase\n",
        "\n",
        "Retourne une liste de tuples : (surface, base_label, start, end) où base_label est par ex. 'LOC' ou 'PERS', et surface est le mot complet extrait du texte (par ex. 'Troiae', 'Lavinia', etc.)."
      ],
      "metadata": {
        "id": "eisTfsqTF6zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_latin_entities(raw_ents, sent_text: str):\n",
        "\n",
        "    if not raw_ents:\n",
        "        return []\n",
        "\n",
        "    sample = raw_ents[0]\n",
        "    if \"entity\" in sample:\n",
        "        label_key = \"entity\"\n",
        "    elif \"entity_group\" in sample:\n",
        "        label_key = \"entity_group\"\n",
        "    else:\n",
        "        label_key = \"label\"\n",
        "\n",
        "    merged_spans = []\n",
        "    current = None\n",
        "\n",
        "    for ent in raw_ents:\n",
        "        full_label = ent[label_key]\n",
        "        base_label = full_label.split(\"-\")[-1]\n",
        "        start, end = ent[\"start\"], ent[\"end\"]\n",
        "\n",
        "        if current is None:\n",
        "            current = {\"label\": base_label, \"start\": start, \"end\": end}\n",
        "        else:\n",
        "            if base_label == current[\"label\"] and start == current[\"end\"]:\n",
        "                current[\"end\"] = end\n",
        "            else:\n",
        "                merged_spans.append(current)\n",
        "                current = {\"label\": base_label, \"start\": start, \"end\": end}\n",
        "\n",
        "    if current is not None:\n",
        "        merged_spans.append(current)\n",
        "\n",
        "    merged_entities = []\n",
        "    n = len(sent_text)\n",
        "\n",
        "    for span in merged_spans:\n",
        "        start = span[\"start\"]\n",
        "        end = span[\"end\"]\n",
        "        label = span[\"label\"]\n",
        "\n",
        "        while start > 0 and sent_text[start - 1].isalpha():\n",
        "            start -= 1\n",
        "\n",
        "        while end < n and sent_text[end].isalpha():\n",
        "            end += 1\n",
        "\n",
        "        surface = sent_text[start:end].strip()\n",
        "        if surface:\n",
        "            merged_entities.append((surface, label, start, end))\n",
        "\n",
        "\n",
        "    return merged_entities"
      ],
      "metadata": {
        "id": "b_KdGlDRyJ5n"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici on va lancer l'analyse globale du texte."
      ],
      "metadata": {
        "id": "fuY_DR3yGVt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "print(\"Nombre de phrases détectées par Stanza :\", len(doc.sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5OFHH4PtoU-",
        "outputId": "2a0922d8-83dd-4b56-fa46-fe5a33a0b2e7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de phrases détectées par Stanza : 4494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essaie de retrouver un lemme Stanza pour une entité NER.\n",
        "\n",
        "*   gère les entités sur un seul mot (Troiae)\n",
        "*   gère les entités multi-mots (ex. 'oris Italiam', 'deos Latio') en testant chaque morceau, en commençant par le dernier (souvent le vrai lieu)."
      ],
      "metadata": {
        "id": "C-6N9DQZGblO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_lemma_by_text(entity_text: str, stanza_sentence) -> str | None:\n",
        "\n",
        "    if not entity_text:\n",
        "        return None\n",
        "\n",
        "    parts = entity_text.split()\n",
        "    candidate_texts = []\n",
        "\n",
        "    if len(parts) == 1:\n",
        "        candidate_texts = [entity_text]\n",
        "    else:\n",
        "        candidate_texts = list(reversed(parts))\n",
        "\n",
        "    for cand in candidate_texts:\n",
        "        ent_norm = normalize_name(cand)\n",
        "        if not ent_norm:\n",
        "            continue\n",
        "\n",
        "        # 1) égalité stricte\n",
        "        for word in stanza_sentence.words:\n",
        "            tok_norm = normalize_name(word.text)\n",
        "            if tok_norm == ent_norm:\n",
        "                return word.lemma.lower()\n",
        "\n",
        "        # 2) entité incluse dans le token\n",
        "        for word in stanza_sentence.words:\n",
        "            tok_norm = normalize_name(word.text)\n",
        "            if ent_norm in tok_norm:\n",
        "                return word.lemma.lower()\n",
        "\n",
        "        # 3) token inclus dans l'entité\n",
        "        for word in stanza_sentence.words:\n",
        "            tok_norm = normalize_name(word.text)\n",
        "            if tok_norm and tok_norm in ent_norm:\n",
        "                return word.lemma.lower()\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "F4aN6EGoi83c"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici on:\n",
        "Construit un dictionnaire :\n",
        "        { lemme_lieu (LOC) -> set({ lemme_personne1, lemme_personne2, ... }) }\n",
        "\n",
        "    - doc  : document Stanza (grec ou latin)\n",
        "    - lang : \"grc\" (grec) ou \"la\" (latin)\n",
        "    - window : (pas utilisé ici, on associe par phrase)\n",
        "    - batch_size : taille des batchs pour Flair (grec)\n",
        "\n",
        "    Dépend de variables globales :\n",
        "    - tagger_grc   (Flair NER grec)         si lang == \"grc\"\n",
        "    - ner_pipe_la  (pipeline HF latin NER)  si lang == \"la\"\n",
        "    - find_lemma_by_text (pour retrouver le lemme Stanza)\n",
        "    - merge_latin_entities (pour fusionner les spans du modèle latin)"
      ],
      "metadata": {
        "id": "2puvwSh1Gzop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_loc_to_pers(doc, lang: str, window: int = 100, batch_size: int = 32):\n",
        "\n",
        "    loc_to_pers = defaultdict(set)\n",
        "\n",
        "    if lang == \"grc\":\n",
        "        if tagger_grc is None:\n",
        "            raise RuntimeError(\"tagger_grc (Flair grec) n'est pas initialisé.\")\n",
        "\n",
        "        flair_sentences = [Sentence(s.text) for s in doc.sentences]\n",
        "        n = len(flair_sentences)\n",
        "        print(\"Grec : nombre de phrases pour Flair :\", n)\n",
        "\n",
        "        for i in tqdm(range(0, n, batch_size), desc=\"NER grec (Flair)\"):\n",
        "            batch_flair = flair_sentences[i:i + batch_size]\n",
        "            batch_stanza = doc.sentences[i:i + batch_size]\n",
        "\n",
        "            tagger_grc.predict(batch_flair, mini_batch_size=batch_size)\n",
        "\n",
        "            for flair_sentence, stanza_sentence in zip(batch_flair, batch_stanza):\n",
        "                loc_texts = []\n",
        "                per_texts = []\n",
        "\n",
        "                for ent in flair_sentence.get_spans(\"ner\"):\n",
        "                    if ent.tag == \"LOC\":\n",
        "                        loc_texts.append(ent.text)\n",
        "                    elif ent.tag == \"PER\":\n",
        "                        per_texts.append(ent.text)\n",
        "\n",
        "                for loc_text in loc_texts:\n",
        "                    loc_lemma = find_lemma_by_text(loc_text, stanza_sentence)\n",
        "                    if not loc_lemma:\n",
        "                        continue\n",
        "                    for per_text in per_texts:\n",
        "                        per_lemma = find_lemma_by_text(per_text, stanza_sentence)\n",
        "                        if per_lemma:\n",
        "                            loc_to_pers[loc_lemma].add(per_lemma)\n",
        "\n",
        "    elif lang == \"la\":\n",
        "        if ner_pipe_la is None:\n",
        "            raise RuntimeError(\"ner_pipe_la (pipeline NER latin) n'est pas initialisé.\")\n",
        "\n",
        "        print(\"Latin : NER phrase par phrase (Transformers + merge_latin_entities).\")\n",
        "        for stanza_sentence in tqdm(doc.sentences, desc=\"NER latin (Transformers)\"):\n",
        "            sent_text = stanza_sentence.text\n",
        "\n",
        "            raw_ents = ner_pipe_la(sent_text)\n",
        "\n",
        "            if not raw_ents:\n",
        "                continue\n",
        "            merged_ents = merge_latin_entities(raw_ents, sent_text)\n",
        "\n",
        "            loc_texts = []\n",
        "            per_texts = []\n",
        "\n",
        "            for surface, base_label, start, end in merged_ents:\n",
        "                if base_label == \"LOC\":\n",
        "                    loc_texts.append(surface)\n",
        "                elif base_label in {\"PERS\", \"PER\", \"PERSON\"}:\n",
        "                    per_texts.append(surface)\n",
        "\n",
        "            for loc_text in loc_texts:\n",
        "                loc_lemma = find_lemma_by_text(loc_text, stanza_sentence)\n",
        "                if not loc_lemma:\n",
        "                    continue\n",
        "                for per_text in per_texts:\n",
        "                    per_lemma = find_lemma_by_text(per_text, stanza_sentence)\n",
        "                    if per_lemma:\n",
        "                        loc_to_pers[loc_lemma].add(per_lemma)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Langue non gérée : {lang} (attendu 'grc' ou 'la')\")\n",
        "\n",
        "    return loc_to_pers"
      ],
      "metadata": {
        "id": "jQ3sZLKDi__r"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loc_to_pers = build_loc_to_pers(doc, LANG, window=100, batch_size=32)"
      ],
      "metadata": {
        "id": "0LdXFO2YjE59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for loc, pers_set in list(loc_to_pers.items()):\n",
        "    print(loc, \":\", pers_set)"
      ],
      "metadata": {
        "id": "2T--k26AjHGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici on nettoie un peu le csv de Pleiades."
      ],
      "metadata": {
        "id": "nWHTZPwVHSNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names_df = pd.read_csv(NAMES_CSV)\n",
        "\n",
        "names_df[\"attested_norm\"] = names_df[\"attested_form\"].apply(normalize_name)\n",
        "\n",
        "for col in [\"romanized_form_1\", \"romanized_form_2\", \"romanized_form_3\"]:\n",
        "    if col in names_df.columns:\n",
        "        names_df[col + \"_norm\"] = names_df[col].fillna(\"\").apply(normalize_name)\n",
        "\n",
        "names_df.head()"
      ],
      "metadata": {
        "id": "6CszvZbtjJop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retourne un place_id Pleiades pour un lemme de lieu, selon la langue.\n",
        "\n",
        "    - grec (\"grc\") : match direct sur les formes grecques, puis translittération grec -> latin\n",
        "    - latin (\"la\") : on ignore un éventuel -us final et on cherche le \"stem\" comme sous-chaîne\n",
        "                     dans attested_norm (d'abord en latin, puis toutes langues)."
      ],
      "metadata": {
        "id": "TgfoSD9LHZz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_place_id_for_loc(loc_lemma: str, names_df: pd.DataFrame, lang: str) -> int | None:\n",
        "\n",
        "    lemma_norm = normalize_name(loc_lemma)\n",
        "\n",
        "\n",
        "    if lang == \"grc\":\n",
        "        greek_mask = names_df[\"language_tag\"] == \"grc\"\n",
        "        match_greek = names_df[greek_mask & (names_df[\"attested_norm\"] == lemma_norm)]\n",
        "        if not match_greek.empty:\n",
        "            return match_greek.iloc[0][\"place_id\"]\n",
        "\n",
        "        latin_guess = transliterate_greek_to_latin(loc_lemma)\n",
        "        roman_cols = [c for c in names_df.columns\n",
        "                      if c.endswith(\"_norm\") and \"romanized_form\" in c]\n",
        "\n",
        "        for col in roman_cols:\n",
        "            match_rom = names_df[names_df[col] == latin_guess]\n",
        "            if not match_rom.empty:\n",
        "                return match_rom.iloc[0][\"place_id\"]\n",
        "\n",
        "        match_attested = names_df[names_df[\"attested_norm\"] == latin_guess]\n",
        "        if not match_attested.empty:\n",
        "            return match_attested.iloc[0][\"place_id\"]\n",
        "\n",
        "        return None\n",
        "\n",
        "    elif lang == \"la\":\n",
        "        stem = lemma_norm\n",
        "        if stem.endswith(\"us\"):\n",
        "            stem = stem[:-2]\n",
        "\n",
        "        if len(stem) < 3:\n",
        "            stem = lemma_norm\n",
        "\n",
        "        latin_mask = names_df[\"language_tag\"] == \"la\"\n",
        "        latin_df = names_df[latin_mask]\n",
        "\n",
        "        match_latin = latin_df[latin_df[\"attested_norm\"].str.contains(stem, na=False)]\n",
        "        if not match_latin.empty:\n",
        "            return match_latin.iloc[0][\"place_id\"]\n",
        "\n",
        "        match_any = names_df[names_df[\"attested_norm\"].str.contains(stem, na=False)]\n",
        "        if not match_any.empty:\n",
        "            return match_any.iloc[0][\"place_id\"]\n",
        "\n",
        "        return None\n",
        "\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "Do_tES3vjV97"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for loc in list(loc_to_pers.keys()):\n",
        "    pid = find_place_id_for_loc(loc, names_df, LANG)\n",
        "    print(loc, \"->\", pid)"
      ],
      "metadata": {
        "id": "ttwFEevPjber"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici on crée une carte Folium à partir de :\n",
        "        loc_to_pers : { lemme_lieu -> { pers_1, pers_2, ... } }\n",
        "        names_df    : données Pleiades (names.csv)\n",
        "        lang        : \"grc\" ou \"la\"\n",
        "\n",
        "    - Fond de carte antique (DARE / Imperium Romanum)\n",
        "    - Fond moderne OSM en option\n",
        "    - Marqueurs personnalisés avec popup (lieu + personnages)"
      ],
      "metadata": {
        "id": "sEIpCy9EHwEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_map_from_loc_to_pers(loc_to_pers, names_df: pd.DataFrame, lang: str) -> folium.Map:\n",
        "\n",
        "\n",
        "    m = folium.Map(location=[37.9838, 23.7275], zoom_start=6, tiles=None)\n",
        "\n",
        "    folium.TileLayer(\n",
        "        tiles=\"https://dh.gu.se/tiles/imperium/{z}/{x}/{y}.png\",\n",
        "        attr=\"DARE / Johan Åhlfeldt, CC-BY\",\n",
        "        name=\"Fond antique (DARE)\",\n",
        "        overlay=False,\n",
        "        control=True,\n",
        "        max_zoom=11,\n",
        "        min_zoom=4,\n",
        "    ).add_to(m)\n",
        "\n",
        "    folium.TileLayer(\n",
        "        \"OpenStreetMap\",\n",
        "        name=\"Fond moderne (OSM)\",\n",
        "        overlay=False,\n",
        "        control=True,\n",
        "    ).add_to(m)\n",
        "\n",
        "    for loc_lemma, pers_set in loc_to_pers.items():\n",
        "        pid = find_place_id_for_loc(loc_lemma, names_df, lang)\n",
        "        if pid is None:\n",
        "            continue\n",
        "\n",
        "        url = f\"http://pleiades.stoa.org/places/{pid}/json\"\n",
        "        try:\n",
        "            pleiades_data = requests.get(url, timeout=10).json()\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] Erreur pour place_id {pid} ({loc_lemma}) :\", e)\n",
        "            continue\n",
        "\n",
        "        repr_point = pleiades_data.get(\"reprPoint\")\n",
        "        if not repr_point:\n",
        "            continue\n",
        "\n",
        "        lon, lat = repr_point\n",
        "\n",
        "        popup_html = f\"\"\"\n",
        "        <b>{loc_lemma}</b><br>\n",
        "        <i>place_id</i> : {pid}<br>\n",
        "        <b>Personnages :</b> {', '.join(sorted(pers_set))}\n",
        "        \"\"\"\n",
        "\n",
        "        folium.Marker(\n",
        "            location=[lat, lon],\n",
        "            popup=popup_html,\n",
        "            icon=folium.Icon(\n",
        "                icon=\"university\",\n",
        "                prefix=\"fa\",\n",
        "                color=\"darkblue\",\n",
        "            ),\n",
        "        ).add_to(m)\n",
        "\n",
        "    folium.LayerControl().add_to(m)\n",
        "    return m"
      ],
      "metadata": {
        "id": "W7s8OtffjiJS"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On crée la carte"
      ],
      "metadata": {
        "id": "d8DazxV8H2BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = make_map_from_loc_to_pers(loc_to_pers, names_df, LANG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1hzO69yji2s",
        "outputId": "f7639ca5-1b0b-440c-f16e-c4d42049746a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Erreur pour place_id 570248 (eurotus) : Response ended prematurely\n",
            "[WARN] Erreur pour place_id 501434 (dardanus) : Response ended prematurely\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On la sauvegarde"
      ],
      "metadata": {
        "id": "PmdAL5eSH3x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m.save(OUTPUT_MAP)"
      ],
      "metadata": {
        "id": "lb8fwPwzjoQG"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puis on recrée un csv : on exporte dans un CSV les données utilisées pour la carte :\n",
        "* lemme du lieu\n",
        "* place_id Pleiades\n",
        "* coordonnées (lat, lon)\n",
        "* personnages associés (séparés par ';')\n",
        "* langue (grc/la)"
      ],
      "metadata": {
        "id": "qU5tWWUqH86T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_map_data_to_csv(loc_to_pers, names_df: pd.DataFrame, lang: str, csv_path: str):\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for loc_lemma, pers_set in loc_to_pers.items():\n",
        "        pid = find_place_id_for_loc(loc_lemma, names_df, lang)\n",
        "        if pid is None:\n",
        "            continue\n",
        "\n",
        "        url = f\"http://pleiades.stoa.org/places/{pid}/json\"\n",
        "        try:\n",
        "            data = requests.get(url, timeout=10).json()\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] Erreur pour place_id {pid} ({loc_lemma}) :\", e)\n",
        "            continue\n",
        "\n",
        "        repr_point = data.get(\"reprPoint\")\n",
        "        if not repr_point:\n",
        "            continue\n",
        "\n",
        "        lon, lat = repr_point\n",
        "\n",
        "        rows.append({\n",
        "            \"loc_lemma\": loc_lemma,\n",
        "            \"place_id\": pid,\n",
        "            \"lat\": lat,\n",
        "            \"lon\": lon,\n",
        "            \"persons\": \";\".join(sorted(pers_set)) if pers_set else \"\",\n",
        "            \"n_persons\": len(pers_set),\n",
        "            \"lang\": lang,\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
        "    print(f\"✔ CSV exporté : {csv_path} ({len(df)} lignes)\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "5PzfljhWjp56"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = f\"map_data_{LANG}.csv\"\n",
        "df_export = export_map_data_to_csv(loc_to_pers, names_df, LANG, csv_path)\n",
        "df_export.head()"
      ],
      "metadata": {
        "id": "7CTD0OfoEio0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et là on va pouvoir refaire une carte à partir du nouveau CSV !"
      ],
      "metadata": {
        "id": "v1hKc1S0IOCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_map_from_csv(csv_path: str, output_html: str | None = None) -> folium.Map:\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    m = folium.Map(location=[37.9838, 23.7275], zoom_start=6, tiles=None)\n",
        "\n",
        "    folium.TileLayer(\n",
        "        tiles=\"https://dh.gu.se/tiles/imperium/{z}/{x}/{y}.png\",\n",
        "        attr=\"DARE / Johan Åhlfeldt, CC-BY\",\n",
        "        name=\"Fond antique (DARE)\",\n",
        "        overlay=False,\n",
        "        control=True,\n",
        "        max_zoom=11,\n",
        "        min_zoom=4,\n",
        "    ).add_to(m)\n",
        "\n",
        "    folium.TileLayer(\n",
        "        \"OpenStreetMap\",\n",
        "        name=\"Fond moderne (OSM)\",\n",
        "        overlay=False,\n",
        "        control=True,\n",
        "    ).add_to(m)\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        loc_lemma = row.get(\"loc_lemma\", \"\")\n",
        "        pid = row.get(\"place_id\", \"\")\n",
        "        lat = row.get(\"lat\", None)\n",
        "        lon = row.get(\"lon\", None)\n",
        "        persons_str = row.get(\"persons\", \"\")\n",
        "\n",
        "        if pd.isna(lat) or pd.isna(lon):\n",
        "            continue\n",
        "\n",
        "        persons_display = persons_str if isinstance(persons_str, str) and persons_str else \"—\"\n",
        "\n",
        "        popup_html = f\"\"\"\n",
        "        <b>{loc_lemma}</b><br>\n",
        "        <i>place_id</i> : {pid}<br>\n",
        "        <b>Personnages :</b> {persons_display}\n",
        "        \"\"\"\n",
        "\n",
        "        folium.Marker(\n",
        "            location=[lat, lon],\n",
        "            popup=popup_html,\n",
        "            icon=folium.Icon(\n",
        "                icon=\"university\",\n",
        "                prefix=\"fa\",\n",
        "                color=\"darkblue\",\n",
        "            ),\n",
        "        ).add_to(m)\n",
        "\n",
        "    folium.LayerControl().add_to(m)\n",
        "\n",
        "    if output_html is not None:\n",
        "        m.save(output_html)\n",
        "        print(f\"✔ Carte sauvegardée dans : {output_html}\")\n",
        "\n",
        "    return m"
      ],
      "metadata": {
        "id": "FPhb81rKEleM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans la cellule suivante vous pourrez mettre votre CSV modifié."
      ],
      "metadata": {
        "id": "MHdfy2ReIWPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "nZ-aFMrDE46r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et là vous obtiendrez une nouvelle carte."
      ],
      "metadata": {
        "id": "JjKe_jPcIbJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_csv = \"map_data_la_filtered.csv\"\n",
        "m_filtered = make_map_from_csv(filtered_csv, output_html=\"map_latin_filtered.html\")"
      ],
      "metadata": {
        "id": "KwQOeTooEwZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et mieux encore, vous allez pouvoir adapter votre CSV à un outil que je vous recommande (et que nous verrons si nous avons le temps), CARTO."
      ],
      "metadata": {
        "id": "ZqErXdggJBQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous trouverez tout ce qu'il faut pour CARTO [ici](https://docs.carto.com/faqs/carto-for-education). C'est un outil hyper pratique et très utile si vous faites de la visualisation précise."
      ],
      "metadata": {
        "id": "ECyZA7-8JOWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"map_data_la.csv\")\n",
        "\n",
        "df_carto = df.rename(columns={\n",
        "    \"lat\": \"latitude\",\n",
        "    \"lon\": \"longitude\",\n",
        "    \"loc_lemma\": \"name\"\n",
        "})\n",
        "\n",
        "df_carto.to_csv(\"map_data_la_carto.csv\", index=False, encoding=\"utf-8\")\n",
        "print(\"CSV prêt pour CARTO : map_data_la_carto.csv\")"
      ],
      "metadata": {
        "id": "2eCnc4tPJJiw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}